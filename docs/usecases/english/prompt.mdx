---
---

# 📜 Prompt Design

**Learn the ins and outs of writing great prompts to get the most out of our models with ✍️ [Create](/api/primitives/create)**.

:::caution ⚠️ Caution
The use of ambiguous, disrespectful, racist, or otherwise improper vocabulary can lead to improper generations. Please use common sense when generating text. LightOn is not responsible for improper use of the Muse API.
:::

Whether you want to use the API to write an article, to answer questions, or to classify customer reviews, it all starts with a **prompt**, i.e. the input text that is submitted to the model and conditions the outputs returned. The prompt primes the model to follow given instructions or perform given tasks, and is primordial to obtain better results.

​In this guide, we review different types of prompts which can be used for Muse, using `lyra-en` as an example. If you're interested in designing prompt in French using `lyra-fr`, check our [Construction de Prompts](/guides/french/prompt) guide! We assume here that the reader is familiar with the use of Create, as well as with the Python Bindings: for more information, check out the ✍️ [Create](/api/primitives/create) and [Python Bindings](/api/bindings/python) documentation pages. We assume that the client has been initialized using

```python
from lightonmuse import Create

creator = Create("lyra-en")
```

​

## A text to complete

​
The first type of prompts we consider here is using the beginning of a text (article, advertisement, literary text) that we want the API to continue.

For example, we can use

```python
prompt = "It was a nice summer evening."
output = creator(prompt, n_tokens=20)
print(prompt + "🤖 " + output[0][0]['completions'][0]['output_text'])
```

​which returns

> It was a nice summer evening.🤖 The sun was setting behind my boat, casting a pink-purple tone over the calm river.

**The quality of the output is strongly conditioned by the quality of your prompt.** In particular, the length, the vocabulary, the grammar of your prompt will have a crucial influence on your output. Just taking the full stop out of the previous prompts changes the text generated by our model:
​

```python
prompt = "It was a nice summer evening"
output = creator(prompt, n_tokens=20)
print(prompt + "🤖 " + output[0][0]['completions'][0]['output_text'])
```

> It was a nice summer evening🤖 . The sky was still bright with orange sun, and on the beach, the sun was fading on

Keep this in mind!

## The description of a task

Another type of prompt that can be used is the description, in natural language, of the task you want Muse to perform. Several examples can also be included to make the generation even more pertinent.

For example, we can ask `lyra-en` to generate an Instagram Ad for a resort that we describe:
​

```python
prompt = "An Instagram ad for Atmosphere resort, a luxury hotel on Apo island in the Philippines with world-class diving.\n\nInstagram Ad:"
output = creator(prompt, temperature=0.8, n_tokens=98, word_biases={"luxury": 5, "scuba": 5}, frequency_penalty=0.5)
print(output[0][0]['completions'][0]['output_text'])
```

> Visit Atmosphere
>
> Atmosphere has just opened its doors and is now ready to offer an unparalleled experience in luxurious, private villas. While the resort’s restaurant is world-class, the real star of the show is the ocean itself. With five stunning dive sites around the island, there’s no better way to enjoy a vacation than with scuba diving. Check out some of our most recent Instagram posts below and get ready to be immersed in paradise!

​Adding examples to the prompt, especially if the task is more complex, improves the generation. Here, we use examples of reviews and their associated answer to prime `lyra-en` to answer customers' reviews.

```python
prompt = """Answer the following client reviews.

###
Review: Really innovative and cool vibe. Cocktails are unusual sounding, but great tasting. We loved the service too, not at all pretentious, friendly and attentive. We’ll be back!
Answer: Thank you for your positive review! We hope to see you again soon :).

###
Review: Great atmosphere. Poor service and drinks.  Waited 45 minutes for our drinks. The mojito was like Sprite with mint garnish.  They didn’t seem to care. For a bar based on cocktails, super poor. Expensive and overrated. Go elsewhere.
Answer: We are sorry we didn't meet your expectations, and that you had to wait for so long. We hope you give us another chance soon.

###
Review: I like this bar. The deco, the staff and the little bit of a mystery in finding it all adds up to a positive experience.
Answer: """
output = creator(prompt, temperature=0.8, n_tokens=25,
                  stop_words=["\n", ".", "\n\n"])
print(output[0][0]['completions'][0]['output_text'])
```

​generates the answer

> Thank you for your kind words! We are glad you liked the ambiance and we look forward to seeing you again.
> ​

to the last review.

​

## Experiment with your prompts

As you can see in the examples above, a good prompt is the key to achieving quality results. The more detail you can include in the description of a task, the more examples you can provide, the better the generation. Make sure to try out various prompts to see what produces the best results for your task at hand, and check out our examples for inspiration.
