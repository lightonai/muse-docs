---
---

# üí¨ Responses

To an HTTP request, the API returns all results formatted in **JSON**.

## Response format

The response is made of three parts:

-   A **`request_id`**, uniquely identifying the request.
-   An **`outputs`** list, containing the model answer to your request, and useful metadata.
-   An **`execution_metadata`** dictionary, with the detailed cost of the request.

Let's have a detailed look at the request example generated on the **[Requests](/api/specifications/requests)** page.

<details>
<summary>Example response (JSON)</summary>

```json
{
    "request_id": "734e8d5a-a186-4d14-b2e4-be26f7fee6dc",
    "outputs": [
        [
            {
                "input_text": "Il √©tait une fois",
                "completions": [
                    {
                        "output_text": ", un pays o√π il faisait toujours beau.\nLes gens y vivaient heureux et en s√©curit√©. Ils avaient de l'argent",
                        "score": {
                            "logprob": -42.8507080078125,
                            "normalized_logprob": -1.7140283203125,
                            "token_logprobs": null
                        },
                        "execution_metadata": {
                            "cost": {
                                "tokens_used": 29,
                                "tokens_input": 4,
                                "tokens_generated": 25,
                                "cost_type": "lyra-fr@default",
                                "batch_size": 1
                            },
                            "finish_reason": "length"
                        }
                    }
                ]
            }
        ]
    ],
    "costs": {
        "lyra-fr@default": {
            "total_tokens_used": 29,
            "total_tokens_input": 4,
            "total_tokens_generated": 25,
            "batch_size": 1
        }
    }
}
```

</details>

## Common structures

### Execution metadata

The `execution_metadata` dictionary collects information relevant to the **cost and execution of the request**. It is
available at the top level, as well as for each individual element of a batch.

-   It contains a `cost` entry, which is a dictionary containing the detailed total cost of the request:

    -   `tokens_used`, the number of tokens used (sum of the next two fields).
    -   `tokens_input`, the number of tokens sent in input to the model.
    -   `tokens_generated`, the number of tokens generated by the model.
    -   `cost_type` in the form `model_name@skill`, indicating the nature of the tokens used (if no skills are used, it will be replaced by `default`).
    -   `batch_size` the number of requests made in a single batch.

-   And a `finish_reason` entry, explaining why the model stopped processing further tokens (`length` if stopped by `n_tokens` or by reaching the end of the text to process, or `stop_word` if reached one of the `stop_words`).

### Score

The `score` dictionary provides information regarding the log-probabilities of the tokens processed:

-   `logprob` is the overall log-probability of the entire text processed.
-   `normalized_logprob` is the same as above, but normalized for text length (number of tokens).
-   `token_logprobs` is a dictionary including the specific log-probability of each token.

## Response to batched requests

The `outputs` list will be structured according to how you have batched your request:

-   It will contain **one separate list for each set of parameters** you have submitted.
-   Each list will contain **one entry per entry in your batch**.
